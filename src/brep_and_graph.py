"""
BREPå›¾æ•°æ®é›†æ¨¡å—

BREPGraphDataset: ä»XMLæ–‡ä»¶åˆ—è¡¨æ„å»ºå›¾æ•°æ®é›†ï¼Œå¯ç›´æ¥ç”¨äºDataLoader
"""

from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union, Callable
from data_preprocess import GraphBuilder
import torch
from torch.utils.data import Dataset
from torch import FloatTensor
import dgl
from concurrent.futures import ProcessPoolExecutor, as_completed


def process_xml_to_graph(xml_path: str) -> Tuple[Optional[dgl.DGLGraph], Dict]:
    """
    å¤„ç†å•ä¸ª XML æ–‡ä»¶ï¼Œè¿”å› DGL å›¾å’Œå…ƒæ•°æ®
    
    Args:
        xml_path: XML æ–‡ä»¶è·¯å¾„
        
    Returns:
        (dgl_graph, metadata): DGL å›¾å’Œå…ƒæ•°æ®å­—å…¸
    """
    xml_file = Path(xml_path)
    
    if not xml_file.exists():
        return None, {
            "source_file": str(xml_path),
            "file_name": xml_file.name,
            "status": "error",
            "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {xml_path}"
        }
    
    try:
        # è¯»å– XML æ–‡ä»¶å†…å®¹
        with open(xml_file, 'r', encoding='utf-8') as f:
            xml_content = f.read()
        
        # ä½¿ç”¨ GraphBuilder ä» XML æ„å»ºå›¾
        graph_builder = GraphBuilder()
        hetero_graph = graph_builder.from_xml(xml_content)
        dgl_graph = hetero_graph.build_dgl_graph()
        
        metadata = {
            "source_file": str(xml_file),
            "file_name": xml_file.name,
            "status": "success",
            "num_nodes": sum(dgl_graph.num_nodes(ntype) for ntype in dgl_graph.ntypes),
            "num_edges": sum(dgl_graph.num_edges(etype) for etype in dgl_graph.canonical_etypes),
            "node_types": list(dgl_graph.ntypes),
            "edge_types": [et[1] for et in dgl_graph.canonical_etypes],
        }
        
        return dgl_graph, metadata
        
    except Exception as e:
        return None, {
            "source_file": str(xml_path),
            "file_name": xml_file.name,
            "status": "error",
            "error": str(e)
        }


def process_xml_files_batch(
    file_paths: List[str], 
    max_workers: int = 4,
    show_progress: bool = True,
    progress_callback: Optional[Callable[[int, int, str], None]] = None
) -> List[Tuple[Optional[dgl.DGLGraph], Dict]]:
    """
    æ‰¹é‡å¤„ç† XML æ–‡ä»¶åˆ—è¡¨
    
    Args:
        file_paths: XML æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        max_workers: æœ€å¤§å¹¶è¡Œè¿›ç¨‹æ•°
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (current, total, message) å‚æ•°
        
    Returns:
        [(dgl_graph, metadata), ...]: ç»“æœåˆ—è¡¨ï¼Œé¡ºåºä¸è¾“å…¥ä¸€è‡´
    """
    if not file_paths:
        return []
    
    # å•æ–‡ä»¶ç›´æ¥å¤„ç†
    if len(file_paths) == 1:
        if progress_callback:
            progress_callback(0, 1, "å¼€å§‹å¤„ç†å•ä¸ªæ–‡ä»¶...")
        result = process_xml_to_graph(file_paths[0])
        if progress_callback:
            progress_callback(1, 1, "å¤„ç†å®Œæˆ")
        return [result]
    
    # å¤šæ–‡ä»¶å¹¶è¡Œå¤„ç†
    results = [None] * len(file_paths)
    total_files = len(file_paths)
    completed_count = 0
    
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤ä»»åŠ¡ï¼Œä¿ç•™ç´¢å¼•
        future_to_idx = {
            executor.submit(process_xml_to_graph, path): idx 
            for idx, path in enumerate(file_paths)
        }
        
        # åˆ›å»ºè¿­ä»£å™¨
        futures = as_completed(future_to_idx)
        if show_progress and not progress_callback:
            try:
                from tqdm import tqdm
                futures = tqdm(futures, total=len(file_paths), desc="å¤„ç†XMLæ–‡ä»¶")
            except ImportError:
                pass
        
        # æ”¶é›†ç»“æœ
        for future in futures:
            idx = future_to_idx[future]
            try:
                results[idx] = future.result()
                completed_count += 1
                if progress_callback:
                    file_name = Path(file_paths[idx]).name
                    progress_callback(completed_count, total_files, f"æ­£åœ¨å¤„ç†: {file_name} ({completed_count}/{total_files})")
            except Exception as e:
                results[idx] = (None, {
                    "source_file": file_paths[idx],
                    "status": "error",
                    "error": str(e)
                })
                completed_count += 1
                if progress_callback:
                    file_name = Path(file_paths[idx]).name
                    progress_callback(completed_count, total_files, f"å¤„ç†å¤±è´¥: {file_name} ({completed_count}/{total_files})")
    
    return results


class BREPGraphDataset(Dataset):
    """
    BREPå›¾æ•°æ®é›† - ä» XML æ–‡ä»¶æ„å»ºå›¾
    
    ä½¿ç”¨å¤šè¿›ç¨‹æ‰¹é‡å¤„ç† XML æ–‡ä»¶
    
    ç”¨æ³•:
        dataset = BREPGraphDataset(file_paths=["a.xml", "b.xml", "c.xml"])
        dataloader = DataLoader(dataset, batch_size=4, collate_fn=dataset.collate_fn)
    """
    
    def __init__(
        self,
        file_paths: List[Union[str, Path]],
        transform=None,
        convert_float32: bool = True,
        max_workers: int = 4,
        progress_callback: Optional[Callable[[int, int, str], None]] = None
    ):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆæ”¯æŒ .xmlï¼‰
            transform: æ•°æ®å˜æ¢å‡½æ•°
            convert_float32: æ˜¯å¦è½¬æ¢ä¸ºfloat32
            max_workers: XMLæ–‡ä»¶å¤„ç†çš„æœ€å¤§å¹¶è¡Œè¿›ç¨‹æ•°
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (current, total, message) å‚æ•°
        """
        self.file_paths = [Path(p) for p in file_paths]
        self.transform = transform
        self.convert_float32 = convert_float32
        self.max_workers = max_workers
        self.progress_callback = progress_callback
        
        # æ•°æ®å­˜å‚¨
        self.data = []
        self.edge_types_dim = {}
        self.node_dim = {}
        
        # åŠ è½½æ‰€æœ‰æ•°æ®
        self._load_all()
        self.edge_types_dim, self.node_dim = self._compute_dims()
    
    def _load_all(self):
        """åŠ è½½æ‰€æœ‰XMLæ–‡ä»¶ï¼ˆå¤šè¿›ç¨‹æ‰¹é‡å¤„ç†ï¼‰"""
        # è¿‡æ»¤æœ‰æ•ˆçš„ XML æ–‡ä»¶
        xml_files = []
        for fp in self.file_paths:
            suffix = fp.suffix.lower()
            if suffix == '.xml':
                xml_files.append(fp)
            else:
                print(f"âš  ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè·³è¿‡: {fp}")
        
        if not xml_files:
            print("âš  æ²¡æœ‰æœ‰æ•ˆçš„XMLæ–‡ä»¶")
            if self.progress_callback:
                self.progress_callback(0, 0, "æ²¡æœ‰æœ‰æ•ˆçš„XMLæ–‡ä»¶")
            return
        
        total_files = len(xml_files)
        print(f"ğŸ“‚ æ‰¹é‡å¤„ç† {total_files} ä¸ªXMLæ–‡ä»¶ï¼ˆ{self.max_workers}è¿›ç¨‹ï¼‰...")
        
        if self.progress_callback:
            self.progress_callback(0, total_files, f"å¼€å§‹å¤„ç† {total_files} ä¸ªæ–‡ä»¶...")
        
        # è°ƒç”¨å¤šè¿›ç¨‹æ‰¹é‡å¤„ç†ï¼Œä¼ å…¥è¿›åº¦å›è°ƒ
        results = process_xml_files_batch(
            [str(fp) for fp in xml_files],
            max_workers=self.max_workers,
            show_progress=False,  # ä¸ä½¿ç”¨tqdmï¼Œä½¿ç”¨è‡ªå®šä¹‰å›è°ƒ
            progress_callback=self.progress_callback
        )
        
        # å¤„ç†ç»“æœ
        processed_count = 0
        for idx, ((graph, metadata), file_path) in enumerate(zip(results, xml_files)):
            if graph is None:
                if self.progress_callback:
                    self.progress_callback(idx + 1, total_files, f"è·³è¿‡æ— æ•ˆæ–‡ä»¶: {file_path.name}")
                continue
            
            if self._is_empty_graph(graph):
                if self.progress_callback:
                    self.progress_callback(idx + 1, total_files, f"è·³è¿‡ç©ºå›¾: {file_path.name}")
                continue
            
            if self.convert_float32:
                graph = self._to_float32(graph)
            
            self.data.append({
                "graph": graph,
                "file_name": file_path.name,  # ä¿å­˜å®Œæ•´æ–‡ä»¶åï¼ˆå«æ‰©å±•åï¼‰
                "metadata": metadata
            })
            processed_count += 1
            
            if self.progress_callback:
                self.progress_callback(idx + 1, total_files, f"å·²å¤„ç† {processed_count}/{total_files} ä¸ªæ–‡ä»¶")
        
        print(f"âœ“ æˆåŠŸåŠ è½½ {len(self.data)}/{total_files} ä¸ªå›¾")
    
    def _is_empty_graph(self, graph: dgl.DGLGraph) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå›¾"""
        if isinstance(graph, dgl.DGLHeteroGraph):
            return sum(graph.num_edges(etype) for etype in graph.canonical_etypes) == 0
        return graph.num_edges() == 0
    
    def _to_float32(self, graph: dgl.DGLGraph) -> dgl.DGLGraph:
        """è½¬æ¢ä¸ºfloat32"""
        for ntype in graph.ntypes:
            if 'x' in graph.nodes[ntype].data:
                graph.nodes[ntype].data['x'] = graph.nodes[ntype].data['x'].type(FloatTensor)
        for etype in graph.canonical_etypes:
            if 'x' in graph.edges[etype].data:
                graph.edges[etype].data['x'] = graph.edges[etype].data['x'].type(FloatTensor)
        return graph
    
    def _compute_dims(self) -> Tuple[Dict, Dict]:
        """è®¡ç®—è¾¹ç±»å‹å’ŒèŠ‚ç‚¹ç±»å‹çš„ç‰¹å¾ç»´åº¦"""
        edge_types_dim = {}
        node_dim = {}
        
        for sample in self.data:
            graph = sample["graph"]
            
            for etype in graph.canonical_etypes:
                if etype not in edge_types_dim:
                    stype, _, _ = etype
                    edge_feat = graph.edges[etype].data.get('x')
                    node_feat = graph.nodes[stype].data.get('x')
                    if edge_feat is not None and node_feat is not None:
                        edge_types_dim[etype] = (edge_feat.shape[1], node_feat.shape[1])
            
            for ntype in graph.ntypes:
                if ntype not in node_dim:
                    feat = graph.nodes[ntype].data.get('x')
                    if feat is not None:
                        node_dim[ntype] = feat.shape[1]
        
        return edge_types_dim, node_dim
    
    def __len__(self) -> int:
        return len(self.data)
    
    def __getitem__(self, idx: int) -> Dict:
        sample = self.data[idx].copy()
        if self.transform and sample.get("graph") is not None:
            sample = self.transform(sample)
        return sample
    
    def get_graphs(self) -> List[dgl.DGLGraph]:
        """è·å–æ‰€æœ‰å›¾å¯¹è±¡"""
        return [sample["graph"] for sample in self.data]
    
    @staticmethod
    def get_graph_info(graph: dgl.DGLGraph) -> Dict:
        """è·å–å›¾çš„è¯¦ç»†ä¿¡æ¯"""
        info = {
            "num_node_types": len(graph.ntypes),
            "num_edge_types": len(graph.canonical_etypes),
            "node_types": {},
            "edge_types": {},
            "total_nodes": 0,
            "total_edges": 0,
        }
        
        for ntype in graph.ntypes:
            num_nodes = graph.num_nodes(ntype)
            feat = graph.nodes[ntype].data.get('x')
            info["node_types"][ntype] = {
                "count": num_nodes,
                "feature_dim": feat.shape[-1] if feat is not None and num_nodes > 0 else 0
            }
            info["total_nodes"] += num_nodes
        
        for etype in graph.canonical_etypes:
            num_edges = graph.num_edges(etype)
            feat = graph.edges[etype].data.get('x')
            info["edge_types"][str(etype)] = {
                "count": num_edges,
                "feature_dim": feat.shape[-1] if feat is not None and num_edges > 0 else 0
            }
            info["total_edges"] += num_edges
        
        return info


def load_single_graph(file_path: Union[str, Path]) -> Tuple[Optional[dgl.DGLGraph], Dict]:
    """
    åŠ è½½å•ä¸ªXMLæ–‡ä»¶çš„ä¾¿æ·å‡½æ•°
    
    Args:
        file_path: XMLæ–‡ä»¶è·¯å¾„ï¼ˆ.xmlï¼‰
        
    Returns:
        (graph, metadata): DGLå›¾å’Œå…ƒæ•°æ®
    """
    file_path = Path(file_path)
    suffix = file_path.suffix.lower()
    
    metadata = {
        "source_file": str(file_path),
        "file_name": file_path.name,
        "status": "processing"
    }
    
    if not file_path.exists():
        metadata["status"] = "error"
        metadata["error"] = f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
        return None, metadata
    
    if suffix != '.xml':
        metadata["status"] = "error"
        metadata["error"] = f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {suffix}ï¼Œä»…æ”¯æŒ .xml"
        return None, metadata
    
    try:
        graph, meta = process_xml_to_graph(str(file_path))
        metadata.update(meta)
        return graph, metadata
    except Exception as e:
        metadata["status"] = "error"
        metadata["error"] = str(e)
        return None, metadata
